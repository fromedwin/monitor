# No version needed in modern Docker Compose

name: fromedwin

services:
  #Crawl4Ai
  crawl4ai:
    image: unclecode/crawl4ai:latest
    container_name: fromedwin-crawl4ai
    ports:
      - "11235:11235"
    networks:
      - monitoring
    volumes:
      - ../worker/crawl4ai/config.yml:/etc/crawl4ai/config.yml:ro
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}

  #
  # Lighthouse is a tool to check website performances
  lighthouse:
    build:
      context: ..
      dockerfile: ./worker/lighthouse/Dockerfile
    networks:
      - monitoring
    user: root
    environment:
      CELERY_BROKER_URL: ${CELERY_BROKER_URL-amqp://admin:adminadmin@rabbitmq}
      BACKEND_URL: ${BACKEND_URL-http://host.docker.internal:8000}
      CHROME_PATH: /usr/lib/chromium/chrome
      SECRET_KEY: ${SECRET_KEY} # Use to authenticate worker queries
    working_dir: /app
    command: ["npm", "start"]
  #
  # Run celery as worker to get tasks from rabbitmq and run them
  #
  worker:
    build:
      context: ..
      dockerfile: Dockerfile
    depends_on:
      crawl4ai:
        condition: service_started
    networks:
      - monitoring
    environment:
      CELERY_BROKER_URL: ${CELERY_BROKER_URL-amqp://admin:adminadmin@rabbitmq}
      SECRET_KEY: ${SECRET_KEY} # Use to authenticate worker queries
      BACKEND_URL: ${BACKEND_URL-http://host.docker.internal:8000}
      DJANGO_SETTINGS_MODULE: "fromedwin.settings.dev"
      DATABASE_URL: ${DATABASE_URL-postgresql://admin:adminadmin@host.docker.internal:5432/fromedwin}
      CRAWL4AI_URL: http://crawl4ai:11235
      CELERYD_CONCURRENCY: ${CELERYD_CONCURRENCY-1} # Only run one worker at a time
      INFLUXDB_URL: ${INFLUXDB_URL-http://influxdb:8086} # access parent container
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN-}
    working_dir: /app/src
    command: ["python", "/app/worker/celery/start_celery_worker.py"]

networks:
  monitoring:
    driver: bridge
